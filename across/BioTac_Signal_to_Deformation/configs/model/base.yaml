activation_layer_0: "ELU"
activation_layer_1: "ELU"
activation_layer_2: "ELU"
activation_layer_3: "ELU"
batch_size: 1024
dropout_layer_0: 0.4
dropout_layer_1: 0.3
dropout_layer_2: 0.2
dropout_layer_3: 0.5
inverse: 1
lr: 0.0005
lr_decay: 1
num_layers: 4
num_neurons_layer_0: 512
num_neurons_layer_1: 128
num_neurons_layer_2: 256
num_neurons_layer_3: 256
weight_decay: 0.0
